title,heading,content,tokens
Kubernetes,Container File System,"A container file system is ephemeral: if a container crashes, the changes to its file system are lost. A volume is defined at the pod level, and is used to preserve data across container crashes. A volume can be also used to share data between containers in a pod. A volume has the same lifecycle as the the pod that encloses it— when a pod is deleted, the volume is deleted as well. Kubernetes supports different volume types, which are implemented as plugins.",112
Kubernetes,Persistent Volume claim,"A persistent volume claim defines a specific amount of storage requested and specific access modes. Kubernetes finds a matching persistent volume and binds it with the persistent volume claim. If a matching volume does not exist, a persistent volume claim will remain unbound indefinitely. It will be bound as soon as a matching volume become available.",76
Kubernetes,Replication Controller,"Designed as a simple building block; a replication controller’s only responsibility is to maintain the specified number of replicas. A replication controller counts only live pods;, terminated pods are excluded. Other Kubernetes building blocks should be used together with replication controllers for more advanced tasks. For example, an autoscaler can monitor applicationspecific metrics and dynamically change the number of replicas in the existing replication controller. In addition, a replication controller does not support scheduling policies, meaning you cannot provide rules for choosing cluster nodes to run pods from the managed set.",120
Kubernetes,Replica Set,"A replica set is another Kubernetes building block. The major difference between it and a replication controller is that replication controllers do not support selectors with set-based requirements, while replica sets support such A Kubernetes selectors. From this perspective, a replica set is just a more advanced version of a replication controller. Using only pods and replication controllers to deploy an application is, at least in part, an imperative form of managing software, because it usually requires manual steps. A Kubernetes deployment is an alternative that enables completely declarative application deployment",120
Kubernetes,Kubernetes Secret,"A Kubernetes secret allows users to pass sensitive information, such as passwords, authentication tokens, SSH keys, and database credentials, to containers. A secret can then be referenced when declaring a container definition, and read from within containers as environment variables or from a local disk.",60
Kubernetes,K8s Config Map,"A Kubernetes config map allows users to externalize application configuration parameters from a container image and define application configuration details, such as key/value pairs, directory content, or file content. Config map values can be consumed by applications through environment variables, local disks, or command line arguments.",60
Kubernetes,Kubernetes Jobs,"A job is used to create one or more pods and ensure that a specified number of them successfully terminate. It tracks the successful completions, and when a specified number of successful completions is reached, the job itself is complete. There are several types of jobs, including non-parallel jobs, parallel jobs with a fixed completion count, and parallel jobs with a work queue. A job should be used instead of a replication controller if you need to spread pods across cluster nodes and ensure, for example, so that each node has only one running pod of the specified type.",132
Kubernetes,Kubernetes Daemon Set,"A daemon set ensures that all or some nodes run a copy of a pod. A daemon set tracks the additional and removal of cluster nodes and adds pods for nodes that are added to the cluster, terminates pods on nodes that are being removed from a cluster. Deleting a daemon set will clean up the pods it created. A typical use case for a daemon set is running a log collection daemon or a monitoring daemon on each node of a cluster.",112
Kubernetes,Imperative vs declarative ,"The classic imperative approach for managing software involves several steps or tasks, some of which are manual. When working in a team, it is usually required that these steps be documented, and, in an ideal case, automated.Preparing good documentation for a classic imperative administrative procedure and automating these steps can be non-trivial tasks, even if each of the steps is simple. A declarative approach for administrative tasks is intended to solve such challenges. With a declarative approach, an administrator defines a target state for a system (application, server, or cluster). Typically, a domain-specific language (DSL) is used to describe the target state. An administrative tool, such as Kubernetes, takes this definition as an input and takes care of how to achieve the target state from the current observable state. ",176
Kubernetes,Development and preparation,"Basic logging in Kubernetes behaves much like logging in Docker. There is a kubectl logs command that will show you all the information written to stdout and stderr for a given container in a pod. If a pod has only one container, there is no need to specify it explicitly, however when a pod has several containers we need to add -c container to the end of the command. As with Docker, we can opt to follow logs, to reduce the number of recent lines with --tail and we can filter them by date. Unlike Docker, Kubernetes enables us to check the logs of a container that crashed using the --previous option. The ability to keep the logs of a previous container is available as long as the pod it was run in remains available. When a pod is removed, so are its logs.",192
Kubernetes,Venues and infrastructure,"As Kubernetes containers are actually Linux processes, we can use our favourite tools to monitor cluster performance. Basic tools, such as top or kubectl top, will behave as expected. It’s also possible to use solutions that are dedicated to Kubernetes. One such solution is Heapster. Heapster aggregates events and data from across the cluster. It runs as a pod in system namespace. Discovery and querying of resources is done automatically with data coming from a kubelet managing node.",104
